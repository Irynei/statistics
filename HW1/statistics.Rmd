---
title: "Statistics | HW1"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

```{r}
# data preprocessing
setwd('C:/Users/ibar/Desktop/UCU/Statistics/statistics/HW1/')
ceodata <- read.csv('ceo.csv')
ceodata$X <- NULL
salary <- ceodata$salary
head(ceodata)
```
# Problem 1

## Task 1

### 1a
```{r}
mean(salary)
```
Mean(2027.517) - average salary.

```{r}
mean.default(salary, trim=0.1)
```
Trimmed mean(1710.092) - mean of salaries without lowest 10% and highest 10% of values.  
Used to eliminate the impact of very large or very small salaries(called outliers) on the mean.

```{r}
median(salary)
```
Median(1600) - central salary. Half of salaries are smaller than median and half are larger.


```{r}
quantile(salary, c(0.25, 0.75))
```
Lower quartile(1084.0) - 25% of salaries are smaller than lower quartile (consequently 75% are larger)  
Upper quartile(2347.5) - 75% of salaries are smaller than upper quartile (consequently 25% are larger)


```{r}
quantile(salary, c(0.1,0.9))
```
Lower 10%-quantile(750.0) - 10% of salaries are smaller than lower quartile (consequently 90% are larger)  
Upper 10%-quantile(3384.4) - 90% of salaries are smaller than upper quartile (consequently 10% are larger)



### 1b

```{r}
Fn <- ecdf(salary)
plot(Fn)
```

Empirical cumulative distribution function of salaries.

```{r}
quantile(salary, c(0.2))
quantile(salary, c(0.8))
Fn(1000)
1 - Fn(5000)
```
*
  $\hat{F}^{-1}(0.2)=976.2$ - 20% of CEOs have at most $976.2 salary.  
  $\hat{F}^{-1}(0.8)=2613$ - 80% of CEOs have at most $2613 salary.

*
  $\hat{F}(1000)=0.223$ - 22.3% of CEOs have at most $1000 salary.  
  $1 - \hat{F}(5000)=0.053$ - 5.3% of CEOs have at least $5000 salary.



### 1c

```{r}
hist(salary, col="darkolivegreen3")
```
```{r}
boxplot(salary, main="Boxplot of salary")
```

As we can see from histogram and boxplot, salary distribution is not symmetric.  
Location measures:  
**mean** is very sensitive to outliers and therefore meaningful only for symmetric data - not appropriate here.  
**trimmed mean** is much more robust to outliers compared to the simple mean - appropriate here.  
**median** is not as strongly influenced by outliers as mean - appropriate here.  
**the interquartile range** is also robust to outliers. There are at least [n/2] of all observations in the interval - appropriate here.  


```{r}
library(moments)
skewness(salary)

```
As a measure of symmetry we can use skewness.
If skewness is larger than zero, then the distribution is right-skewed, therefor salary distribution is right-skewed.



### 1d
```{r}
hist(salary, col="darkolivegreen3")
```

Histogram of salary. Default formula to compute number of bars is Sturges' formula (${\displaystyle k=\lceil \log _{2}n\rceil +1\,}$)  
For salary data $n = `r length(salary)`$, ${\displaystyle k=\lceil \log _{2}`r length(salary)`\rceil +1 = 10\,}$.


```{r}
hist(salary, breaks=4, col="darkolivegreen3")
```

Too rough histogram with only 4 bars.

```{r}
hist(salary, breaks=1000, col="darkolivegreen3")
```

Too detailed histogram with 1000 bars.

We can see that too detailed histogram shows too much individual data and we can't clearly see the underlying pattern.
On the other hand, too rough histogram has only 4 bars and again we are unable to find underlying pattern in the data.



### 1e
```{r}
hist(salary, col="darkolivegreen3")
hist(log(salary), col="tomato", main="Histogram of ln(salary)")
```


```{r}
boxplot(salary, main="Boxplot of salary",col="darkolivegreen3")
```

```{r}
boxplot(log(salary),main="Boxplot of ln(salary)", col="tomato")
```

Boxplot of ln(salary). We can see that this is almost symmetric distribution.


```{r}
mean(log(salary))
median(log(salary))
```
Mean and median of ln(salary).  
In a symmetric distribution, the mean and median fall at the same point.
As we can see mean is pretty much the same as median.



## Task 2

### 2a


```{r}
library(ggplot2)
library(reshape2)
pearson_correlations = cor(ceodata, method="pearson")
qplot(x=Var1, y=Var2, data=melt(pearson_correlations), fill=value, geom="tile") + scale_fill_gradient(low = "white", high = "red")
```



### 2b
```{r}
pairs(~salary + totcomp + tenure + age + sales + profits + assets, data=ceodata, main="CEO Scatterplot Matrix")
```

```{r}
spearman_correlation = cor(ceodata, method="spearman")
qplot(x=Var1, y=Var2, data=melt(spearman_correlation), fill=value, geom="tile") + scale_fill_gradient(low = "white", high = "red")

```



### 2c

```{r}
hist(salary[which(ceodata$age > 50)],  col="darkolivegreen3", main="Age>50 and Age<50 Histograms Of Salary", xlab = "Salary")
hist(salary[which(ceodata$age < 50)],  col="tomato", add=T)
legend("topright", legend=c("Age > 50", "Age < 50"),col=c("darkolivegreen3", "tomato"), lwd=3)
```

```{r}
plot(ecdf(salary[which(ceodata$age > 50)]), col="darkolivegreen3", main="Salary ECDF for Age>50 and Age<50")
plot(ecdf(salary[which(ceodata$age < 50)]), add=T, col="tomato")
legend("bottomright", legend=c("Age > 50", "Age < 50"),col=c("darkolivegreen3", "tomato"), lwd=5)
```

## 3 Task

### 3a
```{r}
grouped_data <- data.frame(salary=ceodata$salary, age=ceodata$age)
# group data by categories 
grouped_data$age <- ifelse(grouped_data$age < 50, "a1", "a2")
grouped_data$salary[suppressWarnings(as.integer(grouped_data$salary)) < 2000] <- "s1"
grouped_data$salary[suppressWarnings(as.integer(grouped_data$salary) >= 2000) & suppressWarnings(as.integer(grouped_data$salary)) < 4000] <- "s2"
grouped_data$salary[suppressWarnings(as.integer(grouped_data$salary)) >= 4000] <- "s3"
```
```{r}
con_table <- xtabs(~age+salary, data=grouped_data)
addmargins(con_table)
```
Contigency table with absolute frequencies.

```{r}
con_table <- xtabs(~age+salary, data=grouped_data)
addmargins(con_table / nrow(grouped_data))
```
Contigency table with relative frequencies.

### 3b


### 3c
```{r}
con_table <- xtabs(~age+salary, data=grouped_data)
chisq.test(con_table)
```

# 2 Problem

## Task 1

### 1a

```{r}
set.seed(19)
simulated <- rnorm(50, 10, 9)
normal <- rnorm(1000000, 10, 9)
hist(simulated, col="darkolivegreen3",prob=TRUE, xlim=c(-40, 40), main="")
lines(density(normal), col="tomato", lwd=2)
legend("topleft", legend=c("N(10,9) histogram", "N(10,9) density"),col=c("darkolivegreen3", "tomato"), lwd=3)

```

```{r}
set.seed(19)
normal <- rnorm(100000, 10, 9)
# simulated_t5 <- dt(x=sample(50), df=5)
simulated_t5 <- rt(50, df=5)
# simulated_t5 <- pt(sample(50), df=5)
simulated_t5 <- 10 + 3 * sqrt(3 / 5) * simulated_t5
hist(simulated_t5, col="darkolivegreen3", prob=TRUE, xlim = c(-5, 25), main="")
lines(density(normal), col="tomato", lwd=2)
legend("topleft", legend=c("transformed t5 hist", "N(10,9) density"),col=c("darkolivegreen3", "tomato"), lwd=3)
```


### 2a
```{r}
set.seed(15)
simulated <- rnorm(50, 10, 9)
list <- c(simulated)
p <- 49
for (i in 0:49){
  list = c(list, 16 + i * (24 - 16)/p)
}
mean(simulated)
mean(list)
median(simulated)
median(list)
var(simulated)
var(list)
boxplot(simulated)
boxplot(list)
```

### 2b, 2c, 2d
Interactive graphics:

* [Boxplot animation](https://irynei.shinyapps.io/boxplot_animation/)  
* [Histogram animation](https://irynei.shinyapps.io/hist_animation/)

```{r}
# library(animation)
# 
# set.seed(15)
# simulated <- rnorm(50, 10, 9)

# saveGIF({
#   for(i in 10:100){
#     distribution = c(simulated, rnorm(i, 20, 4))
#     hist(distribution)
#     abline(v = mean(distribution),col = "royalblue",lwd = 2)
#     abline(v = median(distribution),col = "red",lwd = 2)
#     legend("topright", legend = c(i, "mean", "median"), fill = c("white", "royalblue", "red"), bty = "n")
#       }
# }, movie.name = "hist.gif", interval = 1, ani.width = 550, ani.height = 350)


# saveGIF({
#   for(i in 10:100){
#     boxplot(c(simulated, rnorm(i, 20, 4)))
#     legend("topright", legend = c(i), fill = c("red"), bty = "n")
#       }
# }, movie.name = "boxplot.gif", interval = 1, ani.width = 550, ani.height = 350)

```


### 3b
```{r}
u <- rnorm(50, 0, 1)
set.seed(10)
v <- rnorm(50, 0, 1)
p <- 0.7

v <- p*u + sqrt(1 - p * p) * v


```





### 3a




$$ 
U \sim N(0,1),\ V \sim N(0,1), \\
U^*=U, V^*=\rho U + \sqrt{1-\rho^2} V
$$

Why?

$$ 
Var(X) = E[X^2] - E[X]^2 \\
E[X^2]=Var(X) + E[X]^2 
$$

$$
Var(U^*) = Var(U) = 1 \\
Var(V^*) = E[(V^*)^2] - E[V^*]^2 = E[(\rho U + \sqrt{1-\rho^2}V)^2] - E[\rho U + \sqrt{1-\rho^2}V]^2 = E[(\rho^2 U^2 + (1-\rho^2) V^2 + \rho U \sqrt{1-\rho^2}V)] - (\rho E[U] + \sqrt{1-\rho^2}E[V])^2 = \rho^2 E[U^2] + (1-\rho^2) E[V^2] + \rho \sqrt{1-\rho^2} E[U] E[V] = \rho^2 E[U^2] + (1-\rho) E[V^2] = \rho^2 (Var(U) + E[U]^2) + (1-\rho^2) (Var(V)+E[V]^2)=\rho^2(1+0)+ (1-\rho^2)(1+0)=\rho^2 + 1 - \rho^2=1 
$$

$$ 
Corr(U^*, V^*) = \frac{E[(U^*-E[U^*])(V^*-E[V^*])]}{\sigma_{U^*}\sigma_{V^*}} = E[(U-E[U])(\rho U + \sqrt{1-\rho^2} V - \rho E[U] - \sqrt{1-\rho^2}E[V])] = 
E[U(\rho U + \sqrt{1-\rho^2} V)] = \rho E[U^2] + \sqrt{1-\rho^2} E[U] E[V] = \rho E[U^2] = \rho(Var(U) + E[U]^2) = \rho (1 + 0) = \rho 
$$
